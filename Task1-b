import numpy
%pylab inline --no-import-all
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelBinarizer
## Neural nets
#.....................................
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.optimizers import Adam, SGD

with np.load('training-dataset.npz')  as data:
    img = data['x']
    lbl = data['y']
# Dropping 1 position for prediction label
lbl = lbl-1
for im in range(10):
    image = img[im]
    image = np.array(image, dtype='float')
    pixels = image.reshape((28, 28))
    plt.imshow(pixels)
    plt.show()
# Splitting data into train and test with 80% for training data and 10% for test data

X_train, X_test, y_train, y_test = train_test_split(img, lbl, train_size=0.8, stratify=lbl ,random_state=1) 

# Splitting the train data again into validation and train data with 80% of the train data for training and the 
# remaining 10% for validation purpose

X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=1) 
# Visualising the shape of the train and test data
print(X_train.shape)
print(X_test.shape)
print(X_val.shape)
print(y_test.shape)
print(y_val.shape)
# Preprocessing the data so that it runs faster during fitting the model
# Preprocess the data (these are NumPy arrays)
X_train = X_train.reshape(99840, 784).astype("float32") / 255
X_test = X_test.reshape(12480, 784).astype("float32") / 255
X_val = X_val.reshape(12480, 784).astype("float32") / 255
y_train = y_train.astype("float32")
y_test = y_test.astype("float32")
y_val = y_val.astype("float32")
# One hot decoding 
onehot = LabelBinarizer()
Y_train = onehot.fit_transform(y_train)
Y_val   = onehot.fit_transform(y_val)
Y_test   = onehot.transform(y_test)
# Baseline
baseline = LogisticRegression()
baseline.fit(X_train, y_train)
print(accuracy_score(y_test, baseline.predict(X_test)))
# Fitting the compiling and fitting the sequential model
#.....................................
model = Sequential()
model.add(Dense(80, input_dim=X_train.shape[1], activation='relu'))

model.add(Dense(80, activation='relu'))

model.add(Dense(26, activation='softmax')) # We need to have as many units as classes, 
                                                             # and softmax activation
optimizer = Adam(lr=0.0001)
# For classification, the loss function should be categorical_crossentropy
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics = ['accuracy'])
model.fit(X_train, Y_train, epochs=60, batch_size=64, validation_data=(X_val, Y_val), verbose=1)
# Save the model to disk.
model.save_weights('model.h5')

# Load the model from disk later using:
# model.load_weights('model.h5')

# Predicting the classes on test set and printing the accuracy
y_pred = model.predict_classes(X_test, verbose=1)
print(accuracy_score(y_test, y_pred))
# Evaluating the model
model.evaluate(X_test,Y_test)
# Model summary
model.summary()
print((y_pred[:5]))
print((y_test[:5]))
